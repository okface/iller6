# Iller5: Advanced Study Platform

## 1. Project Overview
Iller5 is a modular, offline-first study web app hosted on GitHub Pages.
- **Goal:** Personal study (Medical exams, Languages, etc.) via flashcards.
- **Privacy:** **Zero** server-side database. All progress is saved in the browser's `localStorage`.
- **Content:** Generated locally via a Python script (using LLM APIs) to prevent API exposure and allow manual review before deployment.

## 2. Tech Stack
- **Frontend:** Vue.js 3 + Vite.
- **Styling:** Tailwind CSS (Mobile-first design).
- **Data Source:** YAML files hosted in the repo.
- **Bundler:** Python script (`scripts/bundle.py`) to compile nature YAMLs into a single `content.json` for the frontend.
- **Deployment:** GitHub Pages (Standard static hosting).
- **Local Tools:** Python 3 (for content generation).

## 3. Data Architecture
The app must support infinite subjects via folder structures.
**Path Pattern:** `data/{Subject_Folder}/{Topic_Filename}.yaml`

**Examples:**
- `data/medical_exam/cardiology.yaml`
- `data/languages/spanish.yaml`

**Question Schema (YAML):**
Each question typically has 4 options. One is correct. VERY CONCISE feedback, few words only.
```yaml
- id: "med-cardio-uniqueID" # Generated by script
  type: "multiple_choice"
  tags: ["Heart Failure", "Pharmacology"] # 1-3 simple tags
  question: "Which medication is contraindicated in..."
  image: "assets/med-cardio-uniqueID.jpg" # Optional. Can be null.
  options:
    - text: "Beta Blockers"
      correct: false
      feedback: "It affects..." 
    - text: "Ace Inhibitors"
      correct: true
      feedback: "..." 
  explanation: "Explains WHY incorrect answers are incorrect in relation to each other, the correct answer and the question. 2-3 sentences max."
```

## 4. The "Factory" (Local Python Script)

File: `scripts/generate.py`
Dependencies: `openai` (v2.0+), `pyyaml`.

**AI Standards (2026):**
- **Model**: `gpt-5-mini` (strictly required). Do not use legacy models like gpt-4o.
- **Client**: Standard `client = OpenAI()`.
- **Params**: 
  - `temperature` is forbidden.
  - `verbosity="low"` (concise output).
  - `reasoning_effort="medium"` (balanced depth).

**Workflow Logic:**

1.  **Selection:** Ask user for Subject (Folder) and Subcategory (Filename).
2.  **Image Check:** Defaults to **NO**. The script will assume text-only generation unless the user explicitly opts-in (e.g., via a prompt that defaults to 'n' or a command line flag).
    - If **Yes**: Instruct LLM to describe images, generate TODO list
    - If **Yes**: The script instructs the LLM to write image descriptions. The script then prints a TODO list for the user to manually add images to `public/assets/`.
3.  **Duplication Check:**
    - Script loads the existing `.yaml` file.
    - Script sends a list of existing question text/IDs to the LLM with the prompt: "Do not generate duplicates of these."
4.  **Generation:**
    - Generates 5-10 questions in valid YAML.
    - Validates structure.
    - Appends to the selected `.yaml` file.

## 5. The "Client" (Web App) Functionality

### A. Dashboard & Study Modes

The home screen should offer these exact options:

1.  **"Quick 5" / "Quick 10":**
    - Pulls questions from ALL categories (or current subject).
    - **CRITICAL:** These buttons must use the SRS Algorithm (see Section B) to select the cards. Do not use pure random.
2.  **"Worst Category (10)":**
    - Scans `localStorage` statistics.
    - Identifies the category/tag with the lowest success rate.
    - Starts a 10-question session for that specific category.
3.  **"Select Category":**
    - User browses Folder -> File (e.g., Medical -> Cardiology).
    - Starts a session for that file.

### B. SRS (Spaced Repetition) Algorithm

We use a lightweight "Bucket System" stored in `localStorage`.

- **Bucket A (High Priority):** New cards OR Cards answered incorrectly last time.
- **Bucket B (Medium):** Cards answered correctly 1 time in a row.
- **Bucket C (Low Priority):** Cards answered correctly 2+ times in a row.

**Selection Weighting:** When a user requests a session (Quick 5/10), the app randomly selects questions based on these probabilities:
- **70%** chance to draw from Bucket A.
- **20%** chance to draw from Bucket B.
- **10%** chance to draw from Bucket C.

### C. The Quiz Interface & Feedback Flow

**Core Principle:** Conciseness.

1.  **Image Rendering:** Check `image` field. If null, render nothing.
2.  **Answering:**
    - User clicks an Option (e.g., Option D).
    - **Visuals:**
        - Selected option (D) turns **Red** (if incorrect) or **Green** (if correct).
        - The Correct option (A) **always** highlights **Green**.
    - **Immediate Text:**
        - If incorrect (D selected, A correct): Show concise reasons "Why D is wrong" AND "Why A is correct".
        - If correct (A selected): Show concise reason "Why A is correct".
    - **General Explanation:** The full explanation text appears at the very bottom (always shown).
3.  **Post-Answer Interaction (The "Why" Feature):**
    - After answering, user remains on the card.
    - User can click the other unselected/unrevealed options (e.g., B and C).
    - Clicking them reveals their specific, concise feedback text ("Why B is wrong").
    - **Goal:** Comprehensive understanding through interactive exploration.

## 6. Deployment

- **Repo:** GitHub.
- **Hosting:** GitHub Pages.
- **Update Workflow:** User pushes new YAML -> GitHub Actions bundles data -> Site updates.